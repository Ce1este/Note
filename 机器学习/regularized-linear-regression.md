# Regularized Linear Regression

## Gradient Descent

We will modify our gradient descent function to separate out $\theta_0$ from the rest of the parameters 
because **we do not want to penalize $\theta_0$**.

Repeat {

$\left.\theta_{0}:=\theta_{0}-\alpha \frac{1}{m} \sum_{i=1}^{m} h_{\theta}\left(x^{(i)}\right)-y^{(i)}\right) x_{0}^{(i)}$

$\left.\theta_{j}:=\theta_{j}-\alpha\left[\left(\frac{1}{m} \sum_{i=1}^{m} h_{\theta}\left(x^{(i)}\right)-y^{(i)}\right) x_{j}^{(i)}\right)+\frac{\lambda}{m} \theta_{j}\right] \quad j \in\{1,2 \ldots n\}$

}

The term $\frac{\lambda}{m}\theta_j$ performs our regularization. 

With some manipulation our update rule can also be represented as:

$\theta_{j}:=\theta_{j}\left(1-\alpha \frac{\lambda}{m}\right)-\alpha \frac{1}{m} \sum_{i=1}^{m}\left(h_{\theta}\left(x^{(i)}\right)-y^{(i)}\right) x_{j}^{(i)}$

The first term in the above equation, $1 - \alpha\frac{\lambda}{m}$ will always be less than 1. 

Intuitively you can see it as reducing the value of $\theta_j$ by some amount on every update. 

Notice that the second term is now exactly the same as it was before.

## Normal Equation

Now let's approach regularization using the alternate method of the non-iterative normal equation.

To add in regularization, the equation is the same as our original, except that we add another term inside the parentheses:

$\theta=\left(X^{T} X+\lambda \cdot L\right)^{1} X^{T} y$

where $L=\left[\begin{array}{cccc}0 & & \\ & 1 & \\ & & 1 \\ & & & \ddots \\ & & & & 1\end{array}\right]$

L is a matrix with 0 at the top left and 1's down the diagonal, with 0's everywhere else. 

It should have **dimension (n+1)×(n+1)**. 

Intuitively, this is the identity matrix (though we are not including $x_0$), multiplied with a single real number λ.

Recall that if m < n, then $X^TX$ is non-invertible. 

However, when we add the term λ⋅L, then $X^TX+ λ⋅L$ becomes invertible.


- back to [[linear-regression]]

[//begin]: # "Autogenerated link references for markdown compatibility"
[linear-regression]: linear-regression "Linear Regression"
[//end]: # "Autogenerated link references"